{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNPW-9PDX31H"
   },
   "source": [
    "## How to do integer encoding using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1685274840976,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "SX1YuKQ4UDon"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import LSTM,Dense , SimpleRNN , Embedding , Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1685274853593,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "KB7xfbIoWmy3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(open('data/train.txt','r').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(open('data/test.txt','r').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(open('data/val.txt','r').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im feeling quite sad and sorry for myself but ill snap out of it soon;sadness\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('data/val.txt','r').readlines()[0]\n",
    "# printing first element of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data from .txt file\n",
    "\n",
    "train = open('data/train.txt','r').readlines()\n",
    "test = open('data/test.txt','r').readlines()\n",
    "val = open('data/val.txt','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = train + test + val\n",
    "len(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating independent and dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting X and Y variable\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for item in full_data:\n",
    "    text,label = item.split(';')\n",
    "    label = label.replace('\\n','')\n",
    "    x.append(text)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will do lowerise all the text\n",
    "# second we will perform word tokenization\n",
    "# third we will remove stopwords\n",
    "# fourth we will perform stemming or lemmataization on each word\n",
    "# then make a clean text \n",
    "stem = PorterStemmer()\n",
    "\n",
    "def text_cleaning(sentences):\n",
    "    clean_text = []\n",
    "    for sent in sentences:\n",
    "        lower_sent = sent.lower()   # first lowerising the sentence\n",
    "        word_tokenize = nltk.word_tokenize(sent)   #performing word_tokenization\n",
    "        removed_stop_words = [word for word in word_tokenize if word not in stopwords.words('english')]  # remove stopwords\n",
    "        stemmed_sent = [stem.stem(word) for word in removed_stop_words]  # apply stemming\n",
    "        cleaned = \" \".join(stemmed_sent)  # joining our final words\n",
    "        clean_text.append(cleaned)      # appending cleaned text in a separate list\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = text_cleaning(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ive been feeling a little burdened lately wasnt sure why that was'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[5]\n",
    "\n",
    "# original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ive feel littl burden late wasnt sure'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[5]\n",
    "# after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3615,
     "status": "ok",
     "timestamp": 1685274921180,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "pOJzJ3vzUOkh"
   },
   "outputs": [],
   "source": [
    "## creating the object Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<nothing>')\n",
    "# we can also pass num_word parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1685274925850,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "njO0da4-Unl8"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(cleaned_data)\n",
    "#we are fitting tokenizer on our cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1685274937992,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "GrKpFbzRUucs",
    "outputId": "3cca0f08-016c-421f-e74b-98addfb6f65f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_index_tokens.lb']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "joblib.dump(tokenizer.word_index,'word_index_tokens.lb')\n",
    "# to check initialize tokens for the word it return a dict, key -> word , value -> initialized token no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1685275001698,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "jNcKSYUYegGl",
    "outputId": "140525ff-bba0-4f95-bafe-f69b3a4e163c"
   },
   "outputs": [],
   "source": [
    "tokenizer.word_counts\n",
    "# to check no. of count of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1685275059288,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "mx3SMLV3euuU",
    "outputId": "86a391e9-e9b7-435f-cfff-2bebd266793f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count\n",
    "# to check total no. of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1685275085970,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "xNrqCeiUU05s",
    "outputId": "6e41c0fb-60e9-45eb-d931-d0e3f0defb80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[61, 2, 522],\n",
       " [10, 2, 419, 682, 67, 50, 60, 96, 1229],\n",
       " [4, 1230, 431, 107, 2, 432, 192],\n",
       " [92, 2, 592, 3696, 7, 21, 2844],\n",
       " [2, 918]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(cleaned_data)\n",
    "sequences[0:5]\n",
    "\n",
    "# tokenize the input sentences as a sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1685275228824,
     "user": {
      "displayName": "Boktiar Ahmed Bappy",
      "userId": "10381972055342951581"
     },
     "user_tz": -360
    },
    "id": "H00D6kZlVOC4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  61,    2,  522,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0],\n",
       "       [  10,    2,  419,  682,   67,   50,   60,   96, 1229,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0],\n",
       "       [   4, 1230,  431,  107,    2,  432,  192,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences,padding='post',maxlen=35)\n",
    "sequences[0:3]\n",
    "# to equalize the length of input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sadness', 'anger', 'love', 'surprise', 'fear', 'joy'], 6)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = list(pd.Series(np.array(y)).unique())\n",
    "no_of_class = len(unique_labels)\n",
    "\n",
    "unique_labels , no_of_class\n",
    "## to finding unique labels and no. of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {\n",
    "    'sadness':0,\n",
    "    'anger':1,\n",
    "    'love':2,\n",
    "    'surprise':3,\n",
    "    'fear':4,\n",
    "    'joy':5\n",
    "}\n",
    "def label_encoder(labels):\n",
    "    label = []\n",
    "    for lab in labels:\n",
    "        label.append(label_dict[lab])\n",
    "    label = np.array(label)\n",
    "    return label\n",
    "\n",
    "label = label_encoder(y)\n",
    "label[0:5]\n",
    "\n",
    "# to perform label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 35), (20000,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape , label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spliting our dataset into train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(sequences,label,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 35), (4000, 35), (4000,), (16000,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,    x_test.shape    ,  y_test.shape    ,  y_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Defining\n",
    "<p>model can be define in a two way.</p>\n",
    "<ul>\n",
    "    <li>sequential model</li>\n",
    "    <li>functional model</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential SimpleRNN model defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                1088      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286\n",
      "Trainable params: 1,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sequential SimpleRNN model defining\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32,input_shape=(35,1),return_sequences=False))\n",
    "model.add(Dense(no_of_class,activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "## compiling the model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "# return_sequence = False  --> means if you don,t want to stack again this model then specify False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 6s 9ms/step - loss: 1.5890 - accuracy: 0.3275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190503450c0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction with SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,   2, 522,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(sequences[0], axis=0)\n",
    "\n",
    "# i am expanding dimension of my numpy array, because model is expecting 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2721405 , 0.15252821, 0.07747145, 0.03647853, 0.1041879 ,\n",
       "        0.3571934 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(np.expand_dims(sequences[5], axis=0))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('joy', 'sadness')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels[np.argmax(pred)]      , unique_labels[label[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the parameters of the Embedding layer and what they do:\n",
    "\n",
    "- input_dim:  This is the size of the vocabulary, i.e., the total number of unique words in your dataset. Each word is assigned a unique integer index. For example, if you have 10,000 unique words, input_dim would be set to 10000.\n",
    "<br>\n",
    "- output_dim: This is the dimension of the dense embedding. It determines the size of the dense vector that will represent each word. A higher value will result in a more expressive representation, but it will also increase the computational complexity of the model.\n",
    "<br>\n",
    "- input_length: This is the length of each input sequence. If you are processing sentences, this would be the number of words in a sentence. For example, if you are using sequences of length 35, you would set input_length=35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    LSTM(units=64, input_shape=(35, 1), return_sequences=True),\n",
    "    LSTM(units=64),\n",
    "    Dense(units=6, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 1.5747 - accuracy: 0.3377\n",
      "Epoch 2/25\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 1.5725 - accuracy: 0.3391\n",
      "Epoch 3/25\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 1.5721 - accuracy: 0.3399\n",
      "Epoch 4/25\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 1.5723 - accuracy: 0.3397\n",
      "Epoch 5/25\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 1.5716 - accuracy: 0.3425\n",
      "Epoch 6/25\n",
      "500/500 [==============================] - 26s 53ms/step - loss: 1.5707 - accuracy: 0.3443\n",
      "Epoch 7/25\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 1.5705 - accuracy: 0.3436\n",
      "Epoch 8/25\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 1.5694 - accuracy: 0.3471\n",
      "Epoch 9/25\n",
      "500/500 [==============================] - 27s 54ms/step - loss: 1.5687 - accuracy: 0.3478\n",
      "Epoch 10/25\n",
      "500/500 [==============================] - 26s 53ms/step - loss: 1.5694 - accuracy: 0.3444\n",
      "Epoch 11/25\n",
      "500/500 [==============================] - 26s 53ms/step - loss: 1.5681 - accuracy: 0.3468\n",
      "Epoch 12/25\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 1.5666 - accuracy: 0.3469\n",
      "Epoch 13/25\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 1.5656 - accuracy: 0.3466\n",
      "Epoch 14/25\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 1.5640 - accuracy: 0.3499\n",
      "Epoch 15/25\n",
      "500/500 [==============================] - 28s 57ms/step - loss: 1.5628 - accuracy: 0.3524\n",
      "Epoch 16/25\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 1.5614 - accuracy: 0.3476\n",
      "Epoch 17/25\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 1.5601 - accuracy: 0.3535\n",
      "Epoch 18/25\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 1.5581 - accuracy: 0.3557\n",
      "Epoch 19/25\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 1.5583 - accuracy: 0.3598\n",
      "Epoch 20/25\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 1.5546 - accuracy: 0.3621\n",
      "Epoch 21/25\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 1.5542 - accuracy: 0.3598\n",
      "Epoch 22/25\n",
      "500/500 [==============================] - 28s 57ms/step - loss: 1.5535 - accuracy: 0.3582\n",
      "Epoch 23/25\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 1.5526 - accuracy: 0.3584\n",
      "Epoch 24/25\n",
      "500/500 [==============================] - 28s 56ms/step - loss: 1.5515 - accuracy: 0.3626\n",
      "Epoch 25/25\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 1.5489 - accuracy: 0.3635\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction With LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 0, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_index = np.argmax(prediction,axis=1)\n",
    "predicted_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 0, ..., 1, 5, 5])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wait for with  embadding layer ðŸ˜‹"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
