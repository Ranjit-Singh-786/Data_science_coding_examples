{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a971f66-6fc2-41c4-a2ee-3a2700463aed",
   "metadata": {},
   "source": [
    ">>> ### Transformers Pipeline power unlocking üîê notebook\n",
    "<h3>To get the solution of all these task with in 1 minute üòã</h3>\n",
    "<ul><li>sentiment-analysis</li>\n",
    "<li>zero-shot-classification</li>\n",
    "<li>text-genration</li>\n",
    "<li>filling-mask</li>\n",
    "<li>NER</li>\n",
    "<li>question-answering</li>\n",
    "<li>summarization</li>\n",
    "<li>language-translation</li>\n",
    "<li>sentence-embedding</li>\n",
    "</ul><br>\n",
    "Please Save This Notebook, and to Reach out me contact on email :- smartengineer0786@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5731dd-986b-4f54-b247-bfba8f35c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ranjit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# pipeline imported to explore the power of nlp with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9599f9-c516-4d1f-b875-b9c84c34a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03535f0-dc1d-4f05-9560-91b5d16849db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Ranjit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n",
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\Ranjit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# pipeline is highlevel Api in transformer library, to perform the NLP tasks with the help of pretrained nlp model\n",
    "# we can write objective inside the pipeline line ssentiment-analysis and\n",
    "# we can also define directly model name here instead of objective, for e.g if you specify the name of the \n",
    "# question answering model, then your pipeline will be created with your model.\n",
    "\n",
    "# I DEFINE PIPELINE WITH OBJECTIVE, I DID NOT DEFINE MODEL INSIDE THE PIPELINE, BUT IF YOU WANT TO \n",
    "# ADD THE MODEL NAME ALSO, YOU CAN USE model= PARAMETER, BUT IF YOU WILL NOT DEFINE THEN IT WILL LOAD\n",
    "# DEFAULT MODELS, WHICH DEFINED BY THE TRANSFORMER LIBRARY.\n",
    "\n",
    "sentiment = pipeline('sentiment-analysis')                            # to perform sentiment analysis\n",
    "zero_shot_classifier = pipeline('zero-shot-classification')           # to perform classification on unseen labels\n",
    "text_generator = pipeline('text-generation')                          #Default --> gpt-2\n",
    "text_generator = pipeline('text-generation',model='distilgpt2')      \n",
    "fill_blanker = pipeline(\"fill-mask\")                                  # TO fill the <Mask> keywords.\n",
    "Ner_recognizer = pipeline('ner',grouped_entities=True)\n",
    "ques_answrng = pipeline(\"question-answering\")                         # question answerin model\n",
    "summeraizer = pipeline(\"summarization\")                               # to generate the text summary\n",
    "translation_pipeline_engl_to_hindi = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\", tokenizer=\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "\n",
    "# all are pipeline imported with specified models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1485b-42a0-4cc9-bbd3-4f34bd6a12fc",
   "metadata": {},
   "source": [
    "### SENTIMENT ANALYSIS\n",
    "\r\n",
    "Sentiment analysis, also known as opinion mining, is the process of using natural language processing and machine learning techniques to determine and extract the emotional tone or sentiment expressed in a piece of text. The goal is to understand whether the text expresses positive, negative, or neutral feelings and to what extent, aiding in the interpretation of subjective information from sources such as social media, customer reviews, or other text-based content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a126721-1245-4415-97d8-9e1cb435e9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9844298362731934}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to perform sentiment analysis for single review\n",
    "sentiment_oupt = sentiment('you are upset, because you loves this product')\n",
    "sentiment_oupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1433381b-7f8b-42cd-8dca-e8561815625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9844298362731934},\n",
       " {'label': 'POSITIVE', 'score': 0.9998668432235718},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994282126426697}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to perform sentiment analysis for single review\n",
    "sentiment_oupt = sentiment(['you are upset, because you loves this product','this one is good one','Indian  politicy is very dirty'])\n",
    "sentiment_oupt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d231c-c58d-401f-a7df-0813b983d471",
   "metadata": {},
   "source": [
    "### ZERO SHOT CLASSIFICATION\n",
    "\r\n",
    "Zero-shot classification is a type of machine learning where a model is trained to categorize input into classes it has never seen before during training. It relies on generalizing from descriptions or attributes provided during training to make predictions for unseen classes at inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00987a5a-1052-4c48-93e6-409de725305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['urgent', 'phone', 'tablet', 'computer', 'not urgent'],\n",
       " 'scores': [0.5794835686683655,\n",
       "  0.36923715472221375,\n",
       "  0.03303714096546173,\n",
       "  0.015176521614193916,\n",
       "  0.0030656903982162476]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classifier(\"I have a problem with my iphone that needs to be resolved asap!!\" ,candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a2260-a5c3-47a3-8b32-639cd1acaa69",
   "metadata": {},
   "source": [
    "### Text-Generation\n",
    "\r\n",
    "The code transformation.pipeline('text-generation') suggests the use of the Hugging Face Transformers library to create a text generation pipeline. In simpler term by default it uses Gpt-2 models:\r\n",
    "\r\n",
    "\"This code initiates a text generation pipeline using the Hugging Face Transformers library, allowing for the generation of text based on pre-trained language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84c8875a-8122-426d-bdc6-3eaabb201d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'i am planing going on vocation for these three different projects.\\n\\nTerrato also called on all of us to make it a priority for all members that share the same mission.\\n\"There is now a real effort in our side'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator('i am planing going on vocation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ad40b33-7656-413b-9062-9c4501589f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'we are going to be one of the ones who is going to keep running, and keep spreading the word,\" he writes.'}, {'generated_text': 'we are going to be interesting to see all of us come together and get real about this project.‚Ä°'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator('we are going to',max_length=30,num_return_sequences=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0b78b-d070-4d2f-9e3f-ae3a07490ab4",
   "metadata": {},
   "source": [
    "### Mask Filling\n",
    "The code pipeline(\"fill-mask\") indicates the use of the Hugging Face Transformers library to create a mask-filling pipeline. In a brief definition:\r\n",
    "\r\n",
    "\"This code initializes a mask-filling pipeline using the Hugging Face Transformers library, enabling the model to predict and fill in missing parts (masked tokens) in a given input text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef379522-710f-4c2a-bf4d-26656b41ffde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.21946614980697632,\n",
       "  'token': 16724,\n",
       "  'token_str': ' camping',\n",
       "  'sequence': 'we are going camping for fun'},\n",
       " {'score': 0.05469982326030731,\n",
       "  'token': 66,\n",
       "  'token_str': ' out',\n",
       "  'sequence': 'we are going out for fun'},\n",
       " {'score': 0.04846232384443283,\n",
       "  'token': 184,\n",
       "  'token_str': ' home',\n",
       "  'sequence': 'we are going home for fun'},\n",
       " {'score': 0.03457130119204521,\n",
       "  'token': 5651,\n",
       "  'token_str': ' fishing',\n",
       "  'sequence': 'we are going fishing for fun'},\n",
       " {'score': 0.03281445801258087,\n",
       "  'token': 15092,\n",
       "  'token_str': ' nuts',\n",
       "  'sequence': 'we are going nuts for fun'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_blanker('we are going <mask> for fun')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "734b0e07-93a7-4815-9ee8-b3958872a9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.21946614980697632,\n",
       "   'token': 16724,\n",
       "   'token_str': ' camping',\n",
       "   'sequence': 'we are going camping for fun'},\n",
       "  {'score': 0.05469982326030731,\n",
       "   'token': 66,\n",
       "   'token_str': ' out',\n",
       "   'sequence': 'we are going out for fun'},\n",
       "  {'score': 0.04846232384443283,\n",
       "   'token': 184,\n",
       "   'token_str': ' home',\n",
       "   'sequence': 'we are going home for fun'},\n",
       "  {'score': 0.03457130119204521,\n",
       "   'token': 5651,\n",
       "   'token_str': ' fishing',\n",
       "   'sequence': 'we are going fishing for fun'},\n",
       "  {'score': 0.03281445801258087,\n",
       "   'token': 15092,\n",
       "   'token_str': ' nuts',\n",
       "   'sequence': 'we are going nuts for fun'}],\n",
       " [{'score': 0.2724287211894989,\n",
       "   'token': 1372,\n",
       "   'token_str': ' happy',\n",
       "   'sequence': 'today i am very happy'},\n",
       "  {'score': 0.12411977350711823,\n",
       "   'token': 7428,\n",
       "   'token_str': ' tired',\n",
       "   'sequence': 'today i am very tired'},\n",
       "  {'score': 0.05598919838666916,\n",
       "   'token': 12025,\n",
       "   'token_str': ' thankful',\n",
       "   'sequence': 'today i am very thankful'},\n",
       "  {'score': 0.054728053510189056,\n",
       "   'token': 6161,\n",
       "   'token_str': ' grateful',\n",
       "   'sequence': 'today i am very grateful'},\n",
       "  {'score': 0.02995654195547104,\n",
       "   'token': 3610,\n",
       "   'token_str': ' busy',\n",
       "   'sequence': 'today i am very busy'}]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_blanker(['we are going <mask> for fun','today i am very <mask>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d261b-3ea1-4335-ad29-fd681f195d8e",
   "metadata": {},
   "source": [
    "### Named Entity Recognition -- NER\n",
    "\n",
    "The code pipeline('ner', grouped_entities=True) suggests the creation of a Named Entity Recognition (NER) pipeline using the Hugging Face Transformers library with the option to group entities. In a concise definition:\r\n",
    "\r\n",
    "\"This code sets up a Named Entity Recognition (NER) pipeline with entity grouping enabled using the Hugging Face Transformers library. The model identifies and classifies named entities in the provided text, and grouped_entities=True implies that it organizes recognized entities into related groups.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39dd6cdb-7403-44ca-b4f7-d05d43311065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99267364,\n",
       "  'word': 'Bhimrao Ramji Ambedkar',\n",
       "  'start': 0,\n",
       "  'end': 22},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99725926,\n",
       "  'word': 'Indian',\n",
       "  'start': 64,\n",
       "  'end': 70},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99034184,\n",
       "  'word': 'Constitution of India',\n",
       "  'start': 166,\n",
       "  'end': 187},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.76282287,\n",
       "  'word': 'Constituen',\n",
       "  'start': 197,\n",
       "  'end': 207},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.714269,\n",
       "  'word': '##t Assembly',\n",
       "  'start': 207,\n",
       "  'end': 217},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.93919915,\n",
       "  'word': 'Law and Justice',\n",
       "  'start': 237,\n",
       "  'end': 252},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9847692,\n",
       "  'word': 'Jawaharlal Nehru',\n",
       "  'start': 286,\n",
       "  'end': 302},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.94286996,\n",
       "  'word': 'Dalit Buddhist',\n",
       "  'start': 321,\n",
       "  'end': 335},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.93374664,\n",
       "  'word': 'Hinduism',\n",
       "  'start': 362,\n",
       "  'end': 370}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"\"\"Bhimrao Ramji Ambedkar (14 April 1891 ‚Äì 6 December 1956) was an Indian jurist, \n",
    "economist, social reformer and political leader who headed the committee drafting the Constitution of India from the Constituent Assembly debates,\n",
    "served as Law and Justice minister in the first cabinet of Jawaharlal Nehru, and inspired the Dalit Buddhist movement after renouncing Hinduism.\"\"\"\n",
    "Ner_recognizer(text_input,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "578aebe9-43fd-47fc-8571-82631a2643c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99267364,\n",
       "  'word': 'Bhimrao Ramji Ambedkar',\n",
       "  'start': 0,\n",
       "  'end': 22},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99725926,\n",
       "  'word': 'Indian',\n",
       "  'start': 64,\n",
       "  'end': 70},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99034184,\n",
       "  'word': 'Constitution of India',\n",
       "  'start': 166,\n",
       "  'end': 187},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.76282287,\n",
       "  'word': 'Constituen',\n",
       "  'start': 197,\n",
       "  'end': 207},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.714269,\n",
       "  'word': '##t Assembly',\n",
       "  'start': 207,\n",
       "  'end': 217},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.93919915,\n",
       "  'word': 'Law and Justice',\n",
       "  'start': 237,\n",
       "  'end': 252},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9847692,\n",
       "  'word': 'Jawaharlal Nehru',\n",
       "  'start': 286,\n",
       "  'end': 302},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.94286996,\n",
       "  'word': 'Dalit Buddhist',\n",
       "  'start': 321,\n",
       "  'end': 335},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.93374664,\n",
       "  'word': 'Hinduism',\n",
       "  'start': 362,\n",
       "  'end': 370}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"\"\"Bhimrao Ramji Ambedkar (14 April 1891 ‚Äì 6 December 1956) was an Indian jurist, \n",
    "economist, social reformer and political leader who headed the committee drafting the Constitution of India from the Constituent Assembly debates,\n",
    "served as Law and Justice minister in the first cabinet of Jawaharlal Nehru, and inspired the Dalit Buddhist movement after renouncing Hinduism.\"\"\"\n",
    "Ner_recognizer(text_input,grouped_entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a819a9a-ea47-4027-8361-65020d99235d",
   "metadata": {},
   "source": [
    "### Language Translation pipeline initialized with eng to hindi translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7356e71-48b4-4ef8-be4d-0fb7f6ae3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Text: where are you going ?\n",
      "[{'translation_text': '‡§§‡•Å‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•ã?'}] \n",
      "\n",
      "['where are you going ?', 'you are very hones person,', 'you are right person.'] \n",
      "\n",
      "Translated Text (English to Hindi): [{'translation_text': '‡§§‡•Å‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•ã?'}, {'translation_text': '‡§§‡•Å‡§Æ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§π‡•â‡§®‡•ç‡§° ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§π‡•ã,'}, {'translation_text': '‡§§‡•Å‡§Æ ‡§∏‡§π‡•Ä ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§π‡•ã.'}]\n"
     ]
    }
   ],
   "source": [
    "# initializing the inputs\n",
    "sentence1 = \"where are you going ?\"\n",
    "sentence2 = \"you are very honest person,\"\n",
    "sentence3  = \"you are right person.\"\n",
    "multiple_sentences = [sentence1,sentence2,sentence3]\n",
    "single_translation = translation_pipeline_engl_to_hindi(sentence1)\n",
    "mltpl_translation = translation_pipeline_engl_to_hindi(multiple_sentences)\n",
    "\n",
    "\n",
    "print(f\"Source Text: {sentence1}\")\n",
    "print(single_translation,'\\n')\n",
    "print(multiple_sentences,'\\n')\n",
    "print(f\"Translated Text (English to Hindi): {mltpl_translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680f23c-19a8-4efc-9c5d-d7a64ef39065",
   "metadata": {},
   "source": [
    "### Working with language Translation LLM\n",
    "you can specify pipeline with this format also, here i have separately loaded the model and the respective tokenizer,\n",
    "and initialized the pipeline with with loaded model and tokenizer, to perform language translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8dbe28c-dcc5-42e6-94ff-382adf20ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranjit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Text: Hello, how are you?\n",
      "Translated Text: [{'translation_text': '‡§π‡•à‡§≤‡•ã, ‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã? - ‡§π‡•à‡§≤‡•ã, ‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# AutoModelForSeq2SeqLM   --> class for load seq2seq RNN Architecture\n",
    "# AutoTokenizer         ---> class for load tokenizer with respective model\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-hi\"      # i picked  this model from huggingface library\n",
    "\n",
    "# Now loading the model using AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Now loading the tokenizer with respective model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Now we are difining translation pipeline with model as well as respective tokenizer\n",
    "translation_pipeline = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Testing pipeline by passing the input \n",
    "source_text = \"Hello, how are you?\"\n",
    "translated_text = translation_pipeline(source_text, max_length=50, min_length=10, return_text=True)\n",
    "\n",
    "print(f\"Source Text: {source_text}\")\n",
    "print(f\"Translated Text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de6259-9bfb-4517-8a19-a485879c4c99",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "summeraizer = pipeline('summarization') <br>\n",
    "in Transformers is like having a smart tool that takes a long piece of text and gives you a short, summarized version that captures the main points. It's like getting the highlights of an article or document without having to read the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "052c0bac-59a5-406f-b3bb-3b35516ff1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Bhimrao Ramji Ambedkar was an Indian jurist, economist, social reformer and political leader . He headed the committee drafting the Constitution of India from the Constituent Assembly debates . In 1956, he converted to Buddhism, initiating mass conversions of Dalits . He inspired the Dalit Buddhist movement after renouncing Hinduism .'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"\"\"Bhimrao Ramji Ambedkar (14 April 1891 ‚Äì 6 December 1956) was an Indian jurist, economist, social reformer and political leader who headed the committee drafting the Constitution of India from the Constituent Assembly debates, served as Law and Justice minister in the first cabinet of Jawaharlal Nehru, and inspired the Dalit Buddhist movement after renouncing Hinduism.\n",
    "\n",
    "After graduating from Elphinstone College, University of Bombay, Ambedkar studied economics at Columbia University and the London School of Economics, receiving doctorates in 1927 and 1923, respectively, and was among a handful of Indian students to have done so at either institution in the 1920s.[3] He also trained in the law at Gray's Inn, London. In his early career, he was an economist, professor, and lawyer. His later life was marked by his political activities; he became involved in campaigning and negotiations for partition, publishing journals, advocating political rights and social freedom for Dalits, and contributing to the establishment of the state of India. In 1956, he converted to Buddhism, initiating mass conversions of Dalits.[4]\n",
    "\n",
    "In 1990, the Bharat Ratna, India's highest civilian award, was posthumously conferred on Ambedkar. The salutation Jai Bhim (lit. \"Hail Bhim\") used by followers honours him. He is also referred to by the nickname Babasaheb (BAH-b…ô SAH-hayb), meaning \"Respected Father\".\"\"\"\n",
    "\n",
    "summeraizer(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6589ab48-ed9c-41ff-bdde-853fb87acf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Bhimrao Ramji Ambedkar was a jurist, economist, social reformer and political leader . He headed the committee'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"\"\"Bhimrao Ramji Ambedkar (14 April 1891 ‚Äì 6 December 1956) was an Indian jurist, economist, social reformer and political leader who headed the committee drafting the Constitution of India from the Constituent Assembly debates, served as Law and Justice minister in the first cabinet of Jawaharlal Nehru, and inspired the Dalit Buddhist movement after renouncing Hinduism.\n",
    "\n",
    "After graduating from Elphinstone College, University of Bombay, Ambedkar studied economics at Columbia University and the London School of Economics, receiving doctorates in 1927 and 1923, respectively, and was among a handful of Indian students to have done so at either institution in the 1920s.[3] He also trained in the law at Gray's Inn, London. In his early career, he was an economist, professor, and lawyer. His later life was marked by his political activities; he became involved in campaigning and negotiations for partition, publishing journals, advocating political rights and social freedom for Dalits, and contributing to the establishment of the state of India. In 1956, he converted to Buddhism, initiating mass conversions of Dalits.[4]\n",
    "\n",
    "In 1990, the Bharat Ratna, India's highest civilian award, was posthumously conferred on Ambedkar. The salutation Jai Bhim (lit. \"Hail Bhim\") used by followers honours him. He is also referred to by the nickname Babasaheb (BAH-b…ô SAH-hayb), meaning \"Respected Father\".\"\"\"\n",
    "\n",
    "summeraizer(input_text,max_length=30,min_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153ce4a-396a-41bd-8abe-d9356d745b16",
   "metadata": {},
   "source": [
    "### question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65642533-024f-43c1-90e8-e45fa1bdf44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9654973149299622, 'start': 24, 'end': 37, 'answer': '14 April 1891'}\n"
     ]
    }
   ],
   "source": [
    "ques_answrng = pipeline(\"question-answering\")                         # question answerin model\n",
    "\n",
    "question = 'when bhimrao ramji ambedkar born ?'\n",
    "context = \"\"\"Bhimrao Ramji Ambedkar (14 April 1891 ‚Äì 6 December 1956) was an Indian jurist, \n",
    "economist, social reformer and political leader who headed the committee drafting the Constitution of India from the Constituent Assembly debates,\n",
    "served as Law and Justice minister in the first cabinet of Jawaharlal Nehru, \n",
    "and inspired the Dalit Buddhist movement after renouncing Hinduism.\n",
    "After graduating from Elphinstone College, University of Bombay,\n",
    "Ambedkar studied economics at Columbia University and the London School of Economics,\n",
    "receiving doctorates in 1927 and 1923, respectively,\n",
    "and was among a handful of Indian students to have done so at either institution in the 1920s.[3] He also trained in the law at Gray's Inn, \n",
    "London. In his early career, he was an economist, professor, and lawyer. His later life was marked by his political activities; he became involved in campaigning and negotiations for partition,\n",
    "publishing journals, advocating political rights and social freedom for Dalits, and contributing to the establishment of the state of India. \n",
    "In 1956, he converted to Buddhism, initiating mass conversions of Dalits.[4]\"\"\"\n",
    "\n",
    "# pass the context and question inside the pipeline, now this pipeline comes with default model and ttokenizer\n",
    "# But if you want to replace the default model with another model, then you should to find name of the model from the huggingface website,\n",
    "# then you can directly define the name of your model and tokenizer inside the pipeline(objective=\"\",model=\"\",tokenizer=\"\") or\n",
    "# you can download model and tokenizer separately then pass inside the ppipeline\n",
    "\n",
    "answer = ques_answrng(question,context)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88db4d7-d014-4c6e-8106-b99194c9b8ce",
   "metadata": {},
   "source": [
    "#### Loading a separate model and tokenizer, to perform the question answering\n",
    "default model with Question answering system is <br>\n",
    "<b>Cased Model:</b><br>\n",
    "A cased model retains the original casing of words in the training data. \n",
    "For example, \"Hello\" and \"hello\" would be treated as distinct tokens.\n",
    "\n",
    "<b>Uncased Model:</b><br>\n",
    "An uncased model, on the other hand, converts all letters to lowercase before processing the text.\n",
    "In this case, \"Hello\" and \"hello\" would be treated as the same token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0187b00a-712a-4bba-9950-bddc4b804654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9254536628723145, 'start': 24, 'end': 37, 'answer': '14 April 1891'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "qus_ans = pipeline('question-answering',model=model,tokenizer=tokenizer)\n",
    "\n",
    "question = 'when bhimrao ramji ambedkar born ?'\n",
    "context = \"\"\"Bhimrao Ramji Ambedkar (14 April 1891 ‚Äì 6 December 1956) was an Indian jurist, \n",
    "economist, social reformer and political leader who headed the committee drafting the Constitution of India from the Constituent Assembly debates,\n",
    "served as Law and Justice minister in the first cabinet of Jawaharlal Nehru, \n",
    "and inspired the Dalit Buddhist movement after renouncing Hinduism.\n",
    "After graduating from Elphinstone College, University of Bombay,\n",
    "Ambedkar studied economics at Columbia University and the London School of Economics,\n",
    "receiving doctorates in 1927 and 1923, respectively,\n",
    "and was among a handful of Indian students to have done so at either institution in the 1920s.[3] He also trained in the law at Gray's Inn, \n",
    "London. In his early career, he was an economist, professor, and lawyer. His later life was marked by his political activities; he became involved in campaigning and negotiations for partition,\n",
    "publishing journals, advocating political rights and social freedom for Dalits, and contributing to the establishment of the state of India. \n",
    "In 1956, he converted to Buddhism, initiating mass conversions of Dalits.[4]\"\"\"\n",
    "\n",
    "answer = qus_ans(question,context)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8278bf-0ba7-4f08-9b70-1425223ee780",
   "metadata": {},
   "source": [
    "### Loading Sentence Embedding model\n",
    "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space<br>\n",
    "and can be used for tasks like clustering or semantic search.<br>\n",
    "Model loaded from hugginghuggingface :- <b>all-MiniLM-L6-v2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc1b7e5-901a-4fea-8616-c02aff81fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3c6cd8-d84a-4fab-868c-bf2b8754d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded the model for sentence embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedding_model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10426ad8-bd87-406e-92fe-a26a88110eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "# Get embedding for single sentence\n",
    "single_embedding = embedding_model.encode('hii , i am army officer')\n",
    "print(type(single_embedding))\n",
    "print(single_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a243f84-f888-4d35-956b-dc5989756540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(4, 384)\n"
     ]
    }
   ],
   "source": [
    "# Get the embedding for multiple Sentences \n",
    "sentences = ['i am Data Scientist enginneer','i am software engineer','i am doctor','i am helpless']\n",
    "embedded_sentences = embedding_model.encode(sentences)\n",
    "print(type(embedded_sentences))\n",
    "print(embedded_sentences.shape)\n",
    "# as you can see the shape for first ---->    384\n",
    "# as you can see the shape for multiple when i pass 4 sentence in a list  ---->  (4, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368971bc-85a1-4fca-aa43-ca8792b6b690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 1, 'score': 0.47091883420944214},\n",
       "  {'corpus_id': 2, 'score': 0.44081127643585205},\n",
       "  {'corpus_id': 0, 'score': 0.3244013488292694},\n",
       "  {'corpus_id': 3, 'score': 0.1895422339439392}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to calculating simlarity in between single sentence to multiple  ssentences\n",
    "simlarity_score  = util.semantic_search(single_embedding,embedded_sentences)\n",
    "simlarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8e2dab2-add6-4ffe-8bf6-bb472a5c67d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3244, 0.4709, 0.4408, 0.1895]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_simlarity_score = util.cos_sim(single_embedding,embedded_sentences)\n",
    "cosine_simlarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225cf5a-24b2-440f-8200-675eb26e6022",
   "metadata": {},
   "source": [
    "## THANK YOU CHECKOUT THIS NOTEBOOK, ü§çü§çü§ç\n",
    "To learn and explore new advance technology in data science , machine learning , computer vision, natural language processing,<br>\n",
    "follow my github <a href=\"https://github.com/Ranjit-Singh-786\"> Github</a> and linkedin <a href=\"https://www.linkedin.com/in/ranjit-singh-423a051a6/\">linkedin</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
